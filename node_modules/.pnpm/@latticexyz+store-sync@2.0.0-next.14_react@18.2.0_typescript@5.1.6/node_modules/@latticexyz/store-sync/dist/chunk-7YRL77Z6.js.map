{"version":3,"sources":["../src/common.ts","../src/flattenSchema.ts","../src/SyncStep.ts","../src/internalTableIds.ts","../src/createStoreSync.ts","../src/debug.ts"],"sourcesContent":["import { Address, Block, Hex, Log, PublicClient } from \"viem\";\nimport { StoreConfig, StoreEventsAbiItem, StoreEventsAbi, resolveConfig } from \"@latticexyz/store\";\nimport { Observable } from \"rxjs\";\nimport { UnionPick } from \"@latticexyz/common/type-utils\";\nimport { KeySchema, TableRecord, ValueSchema } from \"@latticexyz/protocol-parser\";\nimport storeConfig from \"@latticexyz/store/mud.config\";\nimport worldConfig from \"@latticexyz/world/mud.config\";\nimport { flattenSchema } from \"./flattenSchema\";\n\n/** @internal Temporary workaround until we redo our config parsing and can pull this directly from the config (https://github.com/latticexyz/mud/issues/1668) */\nexport const storeTables = resolveConfig(storeConfig).tables;\n/** @internal Temporary workaround until we redo our config parsing and can pull this directly from the config (https://github.com/latticexyz/mud/issues/1668) */\nexport const worldTables = resolveConfig(worldConfig).tables;\n\nexport type ChainId = number;\nexport type WorldId = `${ChainId}:${Address}`;\n\nexport type TableNamespace = string;\nexport type TableName = string;\n\nexport type Table = {\n  address: Address;\n  tableId: Hex;\n  namespace: TableNamespace;\n  name: TableName;\n  keySchema: KeySchema;\n  valueSchema: ValueSchema;\n};\n\nexport type TableWithRecords = Table & { records: TableRecord[] };\n\nexport type StoreEventsLog = Log<bigint, number, false, StoreEventsAbiItem, true, StoreEventsAbi>;\nexport type BlockLogs = { blockNumber: StoreEventsLog[\"blockNumber\"]; logs: StoreEventsLog[] };\n\n// only two keys for now, to reduce complexity of creating indexes on SQL tables\n// TODO: make tableId optional to enable filtering just on keys (any table)\n//       this is blocked on reworking data storage so we can more easily query data across tables\nexport type SyncFilter = {\n  /**\n   * Filter by the `bytes32` table ID.\n   */\n  tableId: Hex;\n  /**\n   * Optionally filter by the `bytes32` value of the key in the first position (index zero of the record's key tuple).\n   */\n  key0?: Hex;\n  /**\n   * Optionally filter by the `bytes32` value of the key in the second position (index one of the record's key tuple).\n   */\n  key1?: Hex;\n};\n\nexport type SyncOptions<TConfig extends StoreConfig = StoreConfig> = {\n  /**\n   * MUD config\n   */\n  config?: TConfig;\n  /**\n   * [viem `PublicClient`][0] used for fetching logs from the RPC.\n   *\n   * [0]: https://viem.sh/docs/clients/public.html\n   */\n  publicClient: PublicClient;\n  /**\n   * MUD Store/World contract address\n   */\n  address?: Address;\n  /**\n   * Optional filters for indexer and RPC state. Useful to narrow down the data received by the client for large worlds.\n   */\n  filters?: SyncFilter[];\n  /**\n   * @deprecated Use `filters` option instead.\n   * */\n  tableIds?: Hex[];\n  /**\n   * Optional block number to start indexing from. Useful for resuming the indexer from a particular point in time or starting after a particular contract deployment.\n   */\n  startBlock?: bigint;\n  /**\n   * Optional maximum block range, if your RPC limits the amount of blocks fetched at a time.\n   */\n  maxBlockRange?: bigint;\n  /**\n   * Optional MUD tRPC indexer URL to fetch initial state from.\n   */\n  indexerUrl?: string;\n  /**\n   * Optional initial state to hydrate from. Useful if you're hydrating from your own indexer or cache.\n   */\n  initialState?: {\n    blockNumber: bigint | null;\n    tables: TableWithRecords[];\n  };\n};\n\nexport type SyncResult = {\n  latestBlock$: Observable<Block>;\n  latestBlockNumber$: Observable<bigint>;\n  blockLogs$: Observable<BlockLogs>;\n  storedBlockLogs$: Observable<StorageAdapterBlock>;\n  waitForTransaction: (tx: Hex) => Promise<void>;\n};\n\n// TODO: add optional, original log to this?\nexport type StorageAdapterLog = Partial<StoreEventsLog> & UnionPick<StoreEventsLog, \"address\" | \"eventName\" | \"args\">;\nexport type StorageAdapterBlock = { blockNumber: BlockLogs[\"blockNumber\"]; logs: StorageAdapterLog[] };\nexport type StorageAdapter = (block: StorageAdapterBlock) => Promise<void>;\n\nexport const schemasTableId = storeTables.Tables.tableId;\nexport const schemasTable = {\n  ...storeTables.Tables,\n  // TODO: remove once we've got everything using the new Table shape\n  keySchema: flattenSchema(storeTables.Tables.keySchema),\n  valueSchema: flattenSchema(storeTables.Tables.valueSchema),\n};\n","import { mapObject } from \"@latticexyz/common/utils\";\nimport { ValueSchema } from \"@latticexyz/store\";\n\nexport function flattenSchema<schema extends ValueSchema>(\n  schema: schema\n): { readonly [k in keyof schema]: schema[k][\"type\"] } {\n  return mapObject(schema, (value) => value.type);\n}\n","export enum SyncStep {\n  INITIALIZE = \"initialize\",\n  SNAPSHOT = \"snapshot\",\n  RPC = \"rpc\",\n  LIVE = \"live\",\n}\n","import { resourceToHex } from \"@latticexyz/common\";\nimport storeConfig from \"@latticexyz/store/mud.config\";\nimport worldConfig from \"@latticexyz/world/mud.config\";\n\n// TODO: refactor config to include table IDs (https://github.com/latticexyz/mud/pull/1561)\n\nexport const storeTableIds = Object.keys(storeConfig.tables).map((name) =>\n  resourceToHex({\n    type: storeConfig.tables[name as keyof typeof storeConfig.tables].offchainOnly ? \"offchainTable\" : \"table\",\n    namespace: storeConfig.namespace,\n    name,\n  })\n);\n\nconst worldTableIds = Object.keys(worldConfig.tables).map((name) =>\n  resourceToHex({\n    type: worldConfig.tables[name as keyof typeof worldConfig.tables].offchainOnly ? \"offchainTable\" : \"table\",\n    namespace: worldConfig.namespace,\n    name,\n  })\n);\n\nexport const internalTableIds = [...storeTableIds, ...worldTableIds];\n","import { StoreConfig, storeEventsAbi } from \"@latticexyz/store\";\nimport { Hex, TransactionReceiptNotFoundError } from \"viem\";\nimport {\n  StorageAdapter,\n  StorageAdapterBlock,\n  StorageAdapterLog,\n  SyncFilter,\n  SyncOptions,\n  SyncResult,\n  TableWithRecords,\n} from \"./common\";\nimport { createBlockStream, blockRangeToLogs, groupLogsByBlockNumber } from \"@latticexyz/block-logs-stream\";\nimport {\n  filter,\n  map,\n  tap,\n  mergeMap,\n  from,\n  concat,\n  concatMap,\n  share,\n  firstValueFrom,\n  defer,\n  of,\n  catchError,\n  shareReplay,\n  combineLatest,\n  scan,\n  identity,\n} from \"rxjs\";\nimport { debug as parentDebug } from \"./debug\";\nimport { createIndexerClient } from \"./trpc-indexer\";\nimport { SyncStep } from \"./SyncStep\";\nimport { chunk, isDefined } from \"@latticexyz/common/utils\";\nimport { encodeKey, encodeValueArgs } from \"@latticexyz/protocol-parser\";\nimport { internalTableIds } from \"./internalTableIds\";\n\nconst debug = parentDebug.extend(\"createStoreSync\");\n\nconst defaultFilters: SyncFilter[] = internalTableIds.map((tableId) => ({ tableId }));\n\ntype CreateStoreSyncOptions<TConfig extends StoreConfig = StoreConfig> = SyncOptions<TConfig> & {\n  storageAdapter: StorageAdapter;\n  onProgress?: (opts: {\n    step: SyncStep;\n    percentage: number;\n    latestBlockNumber: bigint;\n    lastBlockNumberProcessed: bigint;\n    message: string;\n  }) => void;\n};\n\nexport async function createStoreSync<TConfig extends StoreConfig = StoreConfig>({\n  storageAdapter,\n  onProgress,\n  publicClient,\n  address,\n  filters: initialFilters = [],\n  tableIds = [],\n  startBlock: initialStartBlock = 0n,\n  maxBlockRange,\n  initialState,\n  indexerUrl,\n}: CreateStoreSyncOptions<TConfig>): Promise<SyncResult> {\n  const filters: SyncFilter[] =\n    initialFilters.length || tableIds.length\n      ? [...initialFilters, ...tableIds.map((tableId) => ({ tableId })), ...defaultFilters]\n      : [];\n  const initialState$ = defer(\n    async (): Promise<\n      | {\n          blockNumber: bigint | null;\n          tables: TableWithRecords[];\n        }\n      | undefined\n    > => {\n      if (initialState) return initialState;\n      if (!indexerUrl) return;\n\n      debug(\"fetching initial state from indexer\", indexerUrl);\n\n      onProgress?.({\n        step: SyncStep.SNAPSHOT,\n        percentage: 0,\n        latestBlockNumber: 0n,\n        lastBlockNumberProcessed: 0n,\n        message: \"Fetching snapshot from indexer\",\n      });\n\n      const indexer = createIndexerClient({ url: indexerUrl });\n      const chainId = publicClient.chain?.id ?? (await publicClient.getChainId());\n      const result = await indexer.findAll.query({ chainId, address, filters });\n\n      onProgress?.({\n        step: SyncStep.SNAPSHOT,\n        percentage: 100,\n        latestBlockNumber: 0n,\n        lastBlockNumberProcessed: 0n,\n        message: \"Fetched snapshot from indexer\",\n      });\n\n      return result;\n    }\n  ).pipe(\n    catchError((error) => {\n      debug(\"error fetching initial state from indexer\", error);\n\n      onProgress?.({\n        step: SyncStep.SNAPSHOT,\n        percentage: 100,\n        latestBlockNumber: 0n,\n        lastBlockNumberProcessed: initialStartBlock,\n        message: \"Failed to fetch snapshot from indexer\",\n      });\n\n      return of(undefined);\n    }),\n    shareReplay(1)\n  );\n\n  const startBlock$ = initialState$.pipe(\n    map((initialState) => initialState?.blockNumber ?? initialStartBlock),\n    // TODO: if start block is still 0, find via deploy event\n    tap((startBlock) => debug(\"starting sync from block\", startBlock))\n  );\n\n  const initialLogs$ = initialState$.pipe(\n    filter(\n      (initialState): initialState is { blockNumber: bigint; tables: TableWithRecords[] } =>\n        initialState != null && initialState.blockNumber != null && initialState.tables.length > 0\n    ),\n    concatMap(async ({ blockNumber, tables }) => {\n      debug(\"hydrating from initial state to block\", blockNumber);\n\n      onProgress?.({\n        step: SyncStep.SNAPSHOT,\n        percentage: 0,\n        latestBlockNumber: 0n,\n        lastBlockNumberProcessed: blockNumber,\n        message: \"Hydrating from snapshot\",\n      });\n\n      const logs: StorageAdapterLog[] = tables.flatMap((table) =>\n        table.records.map(\n          (record): StorageAdapterLog => ({\n            eventName: \"Store_SetRecord\",\n            address: table.address,\n            args: {\n              tableId: table.tableId,\n              keyTuple: encodeKey(table.keySchema, record.key),\n              ...encodeValueArgs(table.valueSchema, record.value),\n            },\n          })\n        )\n      );\n\n      // Split snapshot operations into chunks so we can update the progress callback (and ultimately render visual progress for the user).\n      // This isn't ideal if we want to e.g. batch load these into a DB in a single DB tx, but we'll take it.\n      //\n      // Split into 50 equal chunks (for better `onProgress` updates) but only if we have 100+ items per chunk\n      const chunkSize = Math.max(100, Math.floor(logs.length / 50));\n      const chunks = Array.from(chunk(logs, chunkSize));\n      for (const [i, chunk] of chunks.entries()) {\n        await storageAdapter({ blockNumber, logs: chunk });\n        onProgress?.({\n          step: SyncStep.SNAPSHOT,\n          percentage: ((i + chunk.length) / chunks.length) * 100,\n          latestBlockNumber: 0n,\n          lastBlockNumberProcessed: blockNumber,\n          message: \"Hydrating from snapshot\",\n        });\n      }\n\n      onProgress?.({\n        step: SyncStep.SNAPSHOT,\n        percentage: 100,\n        latestBlockNumber: 0n,\n        lastBlockNumberProcessed: blockNumber,\n        message: \"Hydrated from snapshot\",\n      });\n\n      return { blockNumber, logs };\n    }),\n    shareReplay(1)\n  );\n\n  const latestBlock$ = createBlockStream({ publicClient, blockTag: \"latest\" }).pipe(shareReplay(1));\n  const latestBlockNumber$ = latestBlock$.pipe(\n    map((block) => block.number),\n    tap((blockNumber) => {\n      debug(\"latest block number\", blockNumber);\n    }),\n    shareReplay(1)\n  );\n\n  let startBlock: bigint | null = null;\n  let endBlock: bigint | null = null;\n  const blockLogs$ = combineLatest([startBlock$, latestBlockNumber$]).pipe(\n    map(([startBlock, endBlock]) => ({ startBlock, endBlock })),\n    tap((range) => {\n      startBlock = range.startBlock;\n      endBlock = range.endBlock;\n    }),\n    blockRangeToLogs({\n      publicClient,\n      address,\n      events: storeEventsAbi,\n      // TODO: pass filters in here so we can filter at RPC level\n      maxBlockRange,\n    }),\n    map(({ toBlock, logs }) => {\n      if (!filters.length) return { toBlock, logs };\n      const filteredLogs = logs.filter((log) =>\n        filters.some(\n          (filter) =>\n            filter.tableId === log.args.tableId &&\n            (filter.key0 == null || filter.key0 === log.args.keyTuple[0]) &&\n            (filter.key1 == null || filter.key1 === log.args.keyTuple[1])\n        )\n      );\n      return { toBlock, logs: filteredLogs };\n    }),\n    mergeMap(({ toBlock, logs }) => from(groupLogsByBlockNumber(logs, toBlock))),\n    share()\n  );\n\n  let lastBlockNumberProcessed: bigint | null = null;\n  const storedBlockLogs$ = concat(\n    initialLogs$,\n    blockLogs$.pipe(\n      concatMap(async (block) => {\n        await storageAdapter(block);\n        return block;\n      }),\n      tap(({ blockNumber, logs }) => {\n        debug(\"stored\", logs.length, \"logs for block\", blockNumber);\n        lastBlockNumberProcessed = blockNumber;\n\n        if (startBlock != null && endBlock != null) {\n          if (blockNumber < endBlock) {\n            const totalBlocks = endBlock - startBlock;\n            const processedBlocks = lastBlockNumberProcessed - startBlock;\n            onProgress?.({\n              step: SyncStep.RPC,\n              percentage: Number((processedBlocks * 1000n) / totalBlocks) / 10,\n              latestBlockNumber: endBlock,\n              lastBlockNumberProcessed,\n              message: \"Hydrating from RPC\",\n            });\n          } else {\n            onProgress?.({\n              step: SyncStep.LIVE,\n              percentage: 100,\n              latestBlockNumber: endBlock,\n              lastBlockNumberProcessed,\n              message: \"All caught up!\",\n            });\n          }\n        }\n      })\n    )\n  ).pipe(share());\n\n  // keep 10 blocks worth processed transactions in memory\n  const recentBlocksWindow = 10;\n  // most recent block first, for ease of pulling the first one off the array\n  const recentBlocks$ = storedBlockLogs$.pipe(\n    scan<StorageAdapterBlock, StorageAdapterBlock[]>(\n      (recentBlocks, block) => [block, ...recentBlocks].slice(0, recentBlocksWindow),\n      []\n    ),\n    filter((recentBlocks) => recentBlocks.length > 0),\n    shareReplay(1)\n  );\n\n  // TODO: move to its own file so we can test it, have its own debug instance, etc.\n  async function waitForTransaction(tx: Hex): Promise<void> {\n    debug(\"waiting for tx\", tx);\n\n    // This currently blocks for async call on each block processed\n    // We could potentially speed this up a tiny bit by racing to see if 1) tx exists in processed block or 2) fetch tx receipt for latest block processed\n    const hasTransaction$ = recentBlocks$.pipe(\n      concatMap(async (blocks) => {\n        const txs = blocks.flatMap((block) => block.logs.map((op) => op.transactionHash).filter(isDefined));\n        if (txs.includes(tx)) return true;\n\n        try {\n          const lastBlock = blocks[0];\n          debug(\"fetching tx receipt for block\", lastBlock.blockNumber);\n          const receipt = await publicClient.getTransactionReceipt({ hash: tx });\n          return lastBlock.blockNumber >= receipt.blockNumber;\n        } catch (error) {\n          if (error instanceof TransactionReceiptNotFoundError) {\n            return false;\n          }\n          throw error;\n        }\n      }),\n      tap((result) => debug(\"has tx?\", tx, result))\n    );\n\n    await firstValueFrom(hasTransaction$.pipe(filter(identity)));\n  }\n\n  return {\n    latestBlock$,\n    latestBlockNumber$,\n    blockLogs$,\n    storedBlockLogs$,\n    waitForTransaction,\n  };\n}\n","import createDebug from \"debug\";\n\nexport const debug = createDebug(\"mud:store-sync\");\n"],"mappings":"wCACA,OAA0D,iBAAAA,MAAqB,oBAI/E,OAAOC,MAAiB,+BACxB,OAAOC,MAAiB,+BCNxB,OAAS,aAAAC,MAAiB,2BAGnB,SAASC,EACdC,EACqD,CACrD,OAAOF,EAAUE,EAASC,GAAUA,EAAM,IAAI,CAChD,CDGO,IAAMC,EAAcC,EAAcC,CAAW,EAAE,OAEzCC,GAAcF,EAAcG,CAAW,EAAE,OAiGzCC,GAAiBL,EAAY,OAAO,QACpCM,GAAe,CAC1B,GAAGN,EAAY,OAEf,UAAWO,EAAcP,EAAY,OAAO,SAAS,EACrD,YAAaO,EAAcP,EAAY,OAAO,WAAW,CAC3D,EEnHO,IAAKQ,OACVA,EAAA,WAAa,aACbA,EAAA,SAAW,WACXA,EAAA,IAAM,MACNA,EAAA,KAAO,OAJGA,OAAA,ICAZ,OAAS,iBAAAC,MAAqB,qBAC9B,OAAOC,MAAiB,+BACxB,OAAOC,MAAiB,+BAIjB,IAAMC,EAAgB,OAAO,KAAKF,EAAY,MAAM,EAAE,IAAKG,GAChEJ,EAAc,CACZ,KAAMC,EAAY,OAAOG,CAAuC,EAAE,aAAe,gBAAkB,QACnG,UAAWH,EAAY,UACvB,KAAAG,CACF,CAAC,CACH,EAEMC,EAAgB,OAAO,KAAKH,EAAY,MAAM,EAAE,IAAKE,GACzDJ,EAAc,CACZ,KAAME,EAAY,OAAOE,CAAuC,EAAE,aAAe,gBAAkB,QACnG,UAAWF,EAAY,UACvB,KAAAE,CACF,CAAC,CACH,EAEaE,EAAmB,CAAC,GAAGH,EAAe,GAAGE,CAAa,ECtBnE,OAAsB,kBAAAE,OAAsB,oBAC5C,OAAc,mCAAAC,OAAuC,OAUrD,OAAS,qBAAAC,GAAmB,oBAAAC,GAAkB,0BAAAC,OAA8B,gCAC5E,OACE,UAAAC,EACA,OAAAC,EACA,OAAAC,EACA,YAAAC,GACA,QAAAC,GACA,UAAAC,GACA,aAAAC,EACA,SAAAC,EACA,kBAAAC,GACA,SAAAC,GACA,MAAAC,GACA,cAAAC,GACA,eAAAC,EACA,iBAAAC,GACA,QAAAC,GACA,YAAAC,OACK,OC7BP,OAAOC,MAAiB,QAEjB,IAAMC,EAAQD,EAAY,gBAAgB,ED+BjD,OAAS,SAAAE,GAAO,aAAAC,OAAiB,2BACjC,OAAS,aAAAC,GAAW,mBAAAC,OAAuB,8BAG3C,IAAMC,EAAQA,EAAY,OAAO,iBAAiB,EAE5CC,GAA+BC,EAAiB,IAAKC,IAAa,CAAE,QAAAA,CAAQ,EAAE,EAapF,eAAsBC,GAA2D,CAC/E,eAAAC,EACA,WAAAC,EACA,aAAAC,EACA,QAAAC,EACA,QAASC,EAAiB,CAAC,EAC3B,SAAAC,EAAW,CAAC,EACZ,WAAYC,EAAoB,GAChC,cAAAC,EACA,aAAAC,EACA,WAAAC,CACF,EAAyD,CACvD,IAAMC,EACJN,EAAe,QAAUC,EAAS,OAC9B,CAAC,GAAGD,EAAgB,GAAGC,EAAS,IAAKP,IAAa,CAAE,QAAAA,CAAQ,EAAE,EAAG,GAAGF,EAAc,EAClF,CAAC,EACDe,EAAgBC,GACpB,SAMK,CACH,GAAIJ,EAAc,OAAOA,EACzB,GAAI,CAACC,EAAY,OAEjBd,EAAM,sCAAuCc,CAAU,EAEvDR,IAAa,CACX,gBACA,WAAY,EACZ,kBAAmB,GACnB,yBAA0B,GAC1B,QAAS,gCACX,CAAC,EAED,IAAMY,EAAUC,EAAoB,CAAE,IAAKL,CAAW,CAAC,EACjDM,EAAUb,EAAa,OAAO,IAAO,MAAMA,EAAa,WAAW,EACnEc,EAAS,MAAMH,EAAQ,QAAQ,MAAM,CAAE,QAAAE,EAAS,QAAAZ,EAAS,QAAAO,CAAQ,CAAC,EAExE,OAAAT,IAAa,CACX,gBACA,WAAY,IACZ,kBAAmB,GACnB,yBAA0B,GAC1B,QAAS,+BACX,CAAC,EAEMe,CACT,CACF,EAAE,KACAC,GAAYC,IACVvB,EAAM,4CAA6CuB,CAAK,EAExDjB,IAAa,CACX,gBACA,WAAY,IACZ,kBAAmB,GACnB,yBAA0BK,EAC1B,QAAS,uCACX,CAAC,EAEMa,GAAG,MAAS,EACpB,EACDC,EAAY,CAAC,CACf,EAEMC,EAAcV,EAAc,KAChCW,EAAKd,GAAiBA,GAAc,aAAeF,CAAiB,EAEpEiB,EAAKC,GAAe7B,EAAM,2BAA4B6B,CAAU,CAAC,CACnE,EAEMC,EAAed,EAAc,KACjCe,EACGlB,GACCA,GAAgB,MAAQA,EAAa,aAAe,MAAQA,EAAa,OAAO,OAAS,CAC7F,EACAmB,EAAU,MAAO,CAAE,YAAAC,EAAa,OAAAC,CAAO,IAAM,CAC3ClC,EAAM,wCAAyCiC,CAAW,EAE1D3B,IAAa,CACX,gBACA,WAAY,EACZ,kBAAmB,GACnB,yBAA0B2B,EAC1B,QAAS,yBACX,CAAC,EAED,IAAME,EAA4BD,EAAO,QAASE,GAChDA,EAAM,QAAQ,IACXC,IAA+B,CAC9B,UAAW,kBACX,QAASD,EAAM,QACf,KAAM,CACJ,QAASA,EAAM,QACf,SAAUE,GAAUF,EAAM,UAAWC,EAAO,GAAG,EAC/C,GAAGE,GAAgBH,EAAM,YAAaC,EAAO,KAAK,CACpD,CACF,EACF,CACF,EAMMG,EAAY,KAAK,IAAI,IAAK,KAAK,MAAML,EAAK,OAAS,EAAE,CAAC,EACtDM,EAAS,MAAM,KAAKC,GAAMP,EAAMK,CAAS,CAAC,EAChD,OAAW,CAACG,EAAGD,CAAK,IAAKD,EAAO,QAAQ,EACtC,MAAMpC,EAAe,CAAE,YAAA4B,EAAa,KAAMS,CAAM,CAAC,EACjDpC,IAAa,CACX,gBACA,YAAcqC,EAAID,EAAM,QAAUD,EAAO,OAAU,IACnD,kBAAmB,GACnB,yBAA0BR,EAC1B,QAAS,yBACX,CAAC,EAGH,OAAA3B,IAAa,CACX,gBACA,WAAY,IACZ,kBAAmB,GACnB,yBAA0B2B,EAC1B,QAAS,wBACX,CAAC,EAEM,CAAE,YAAAA,EAAa,KAAAE,CAAK,CAC7B,CAAC,EACDV,EAAY,CAAC,CACf,EAEMmB,EAAeC,GAAkB,CAAE,aAAAtC,EAAc,SAAU,QAAS,CAAC,EAAE,KAAKkB,EAAY,CAAC,CAAC,EAC1FqB,EAAqBF,EAAa,KACtCjB,EAAKoB,GAAUA,EAAM,MAAM,EAC3BnB,EAAKK,GAAgB,CACnBjC,EAAM,sBAAuBiC,CAAW,CAC1C,CAAC,EACDR,EAAY,CAAC,CACf,EAEII,EAA4B,KAC5BmB,EAA0B,KACxBC,EAAaC,GAAc,CAACxB,EAAaoB,CAAkB,CAAC,EAAE,KAClEnB,EAAI,CAAC,CAACE,EAAYmB,CAAQ,KAAO,CAAE,WAAAnB,EAAY,SAAAmB,CAAS,EAAE,EAC1DpB,EAAKuB,GAAU,CACbtB,EAAasB,EAAM,WACnBH,EAAWG,EAAM,QACnB,CAAC,EACDC,GAAiB,CACf,aAAA7C,EACA,QAAAC,EACA,OAAQ6C,GAER,cAAAzC,CACF,CAAC,EACDe,EAAI,CAAC,CAAE,QAAA2B,EAAS,KAAAnB,CAAK,IAAM,CACzB,GAAI,CAACpB,EAAQ,OAAQ,MAAO,CAAE,QAAAuC,EAAS,KAAAnB,CAAK,EAC5C,IAAMoB,EAAepB,EAAK,OAAQqB,GAChCzC,EAAQ,KACLgB,GACCA,EAAO,UAAYyB,EAAI,KAAK,UAC3BzB,EAAO,MAAQ,MAAQA,EAAO,OAASyB,EAAI,KAAK,SAAS,CAAC,KAC1DzB,EAAO,MAAQ,MAAQA,EAAO,OAASyB,EAAI,KAAK,SAAS,CAAC,EAC/D,CACF,EACA,MAAO,CAAE,QAAAF,EAAS,KAAMC,CAAa,CACvC,CAAC,EACDE,GAAS,CAAC,CAAE,QAAAH,EAAS,KAAAnB,CAAK,IAAMuB,GAAKC,GAAuBxB,EAAMmB,CAAO,CAAC,CAAC,EAC3EM,EAAM,CACR,EAEIC,EAA0C,KACxCC,EAAmBC,GACvBjC,EACAmB,EAAW,KACTjB,EAAU,MAAOe,IACf,MAAM1C,EAAe0C,CAAK,EACnBA,EACR,EACDnB,EAAI,CAAC,CAAE,YAAAK,EAAa,KAAAE,CAAK,IAAM,CAI7B,GAHAnC,EAAM,SAAUmC,EAAK,OAAQ,iBAAkBF,CAAW,EAC1D4B,EAA2B5B,EAEvBJ,GAAc,MAAQmB,GAAY,KACpC,GAAIf,EAAce,EAAU,CAC1B,IAAMgB,EAAchB,EAAWnB,EACzBoC,EAAkBJ,EAA2BhC,EACnDvB,IAAa,CACX,WACA,WAAY,OAAQ2D,EAAkB,MAASD,CAAW,EAAI,GAC9D,kBAAmBhB,EACnB,yBAAAa,EACA,QAAS,oBACX,CAAC,OAEDvD,IAAa,CACX,YACA,WAAY,IACZ,kBAAmB0C,EACnB,yBAAAa,EACA,QAAS,gBACX,CAAC,CAGP,CAAC,CACH,CACF,EAAE,KAAKD,EAAM,CAAC,EAGRM,EAAqB,GAErBC,EAAgBL,EAAiB,KACrCM,GACE,CAACC,EAActB,IAAU,CAACA,EAAO,GAAGsB,CAAY,EAAE,MAAM,EAAGH,CAAkB,EAC7E,CAAC,CACH,EACAnC,EAAQsC,GAAiBA,EAAa,OAAS,CAAC,EAChD5C,EAAY,CAAC,CACf,EAGA,eAAe6C,EAAmBC,EAAwB,CACxDvE,EAAM,iBAAkBuE,CAAE,EAI1B,IAAMC,EAAkBL,EAAc,KACpCnC,EAAU,MAAOyC,GAAW,CAE1B,GADYA,EAAO,QAAS1B,GAAUA,EAAM,KAAK,IAAK2B,GAAOA,EAAG,eAAe,EAAE,OAAOC,EAAS,CAAC,EAC1F,SAASJ,CAAE,EAAG,MAAO,GAE7B,GAAI,CACF,IAAMK,EAAYH,EAAO,CAAC,EAC1BzE,EAAM,gCAAiC4E,EAAU,WAAW,EAC5D,IAAMC,EAAU,MAAMtE,EAAa,sBAAsB,CAAE,KAAMgE,CAAG,CAAC,EACrE,OAAOK,EAAU,aAAeC,EAAQ,WAC1C,OAAStD,EAAP,CACA,GAAIA,aAAiBuD,GACnB,MAAO,GAET,MAAMvD,CACR,CACF,CAAC,EACDK,EAAKP,GAAWrB,EAAM,UAAWuE,EAAIlD,CAAM,CAAC,CAC9C,EAEA,MAAM0D,GAAeP,EAAgB,KAAKzC,EAAOiD,EAAQ,CAAC,CAAC,CAC7D,CAEA,MAAO,CACL,aAAApC,EACA,mBAAAE,EACA,WAAAG,EACA,iBAAAa,EACA,mBAAAQ,CACF,CACF","names":["resolveConfig","storeConfig","worldConfig","mapObject","flattenSchema","schema","value","storeTables","resolveConfig","storeConfig","worldTables","worldConfig","schemasTableId","schemasTable","flattenSchema","SyncStep","resourceToHex","storeConfig","worldConfig","storeTableIds","name","worldTableIds","internalTableIds","storeEventsAbi","TransactionReceiptNotFoundError","createBlockStream","blockRangeToLogs","groupLogsByBlockNumber","filter","map","tap","mergeMap","from","concat","concatMap","share","firstValueFrom","defer","of","catchError","shareReplay","combineLatest","scan","identity","createDebug","debug","chunk","isDefined","encodeKey","encodeValueArgs","debug","defaultFilters","internalTableIds","tableId","createStoreSync","storageAdapter","onProgress","publicClient","address","initialFilters","tableIds","initialStartBlock","maxBlockRange","initialState","indexerUrl","filters","initialState$","defer","indexer","createIndexerClient","chainId","result","catchError","error","of","shareReplay","startBlock$","map","tap","startBlock","initialLogs$","filter","concatMap","blockNumber","tables","logs","table","record","encodeKey","encodeValueArgs","chunkSize","chunks","chunk","i","latestBlock$","createBlockStream","latestBlockNumber$","block","endBlock","blockLogs$","combineLatest","range","blockRangeToLogs","storeEventsAbi","toBlock","filteredLogs","log","mergeMap","from","groupLogsByBlockNumber","share","lastBlockNumberProcessed","storedBlockLogs$","concat","totalBlocks","processedBlocks","recentBlocksWindow","recentBlocks$","scan","recentBlocks","waitForTransaction","tx","hasTransaction$","blocks","op","isDefined","lastBlock","receipt","TransactionReceiptNotFoundError","firstValueFrom","identity"]}